## 2018-05-04

I'm thinking that for each exchange we can have 2 files. The first
'scannerPoloniex.js' will be run 24/7 and will..
- periodically receive the 'pairsPoloniex.json' file
- cycle through the pairs list
- receive ticker data
- convert to consistent format
- save to storage

This way, if something happens which causes our program to break, it will only
affect one exchange. Or if we need to update, we just need to stop collecting
on one exchange at a time. And we can always update the pairs we're following
without interrupting the scanner.

This will be what I'll be working on for now. I'll create an Archives/ directory
and store the old scanner.js and pairs.js there for reference.

## 2018-06-09

Poloniex is working now. There might still be some small bugs. I'm gonna hold
out a while and improve the Poloniex scanner before trying Binance.

## 2018-06-10

I ran a test of Poloniex scanner v1.0.1 last night for 12 hours on 10 pairs on
my Amazon AWS EC2 instance. Everything seemed to work fine. I was able to
approximate the size of 1 day for 1 pair to be around 0.48 MB if we are saving
candle data every 15 seconds.

So let's say we store 100 pairs for 1 year. That would be about
`0.48*100*365 = 17,520` MB or around 18 GB.
So to store 100 pairs will cost about 18 GB/yr for storage. (A first
approximation)
So therefore 1 TB of storage space would last us around 56 years (lol)

## 2018-06-10

I also did a test today regarding how much data we should store in 1 file.
First off, a day of data is about 2900 lines and about half a MB. Once you
start dealing with several days in the same csv document you experience lag
opening the file, copy/pasting contents, and saving the file. Storing 2 weeks
on the same text file is manageable in spite of the lag but probably not
preferred.

I've been thinking it's probably best to split the days like we split the
months...

Poloniex/
  BTCUSD/
    2018/
      5/
        1.csv
        2.csv
        3.csv
        4.csv

or better yet...

Poloniex/
  BTCUSD/
    2018/
      4-31.csv
      5-1.csv
      5-2.csv
      5-3.csv

but I would also like to adjust the month so it goes from 1-12 instead of 0-11..

Poloniex/
  BTCUSD/
    2018/
      5-31.csv
      6-1.csv
      6-2.csv

## 2018-06-13

Well I left the Poloniex data retreiver running for a few days. Turns out the
WS was suddenly closed for no obvious reason. In v1.0.4 I made sure to print
the reason to log and also attempt to reconnect. So now I can try another
multi-day test.

I will also start working on Binance. Poloniex seems sufficiently far along.
Binance will be considered in beta during the remainder of v1.0 and will be
officially functional at v1.1

## 2018-06-14

Well apparently it's only one day later and a lot has changed. Current version
is v1.0.6 and Binance and Bitfinex are expected to be functional. I need to
figure out how to test them at the same time I'm testing Poloniex, because
I'm still trying to properly troubleshoot errors on Poloniex.

I'm going to add Coinbase (GDAX) next. Hopefully the API won't change much when
they change their name to Coinbase Pro. Then once I have 4 exchanges I think I
will call it good for now. I will just keep improving the 4 instead of adding
new exchanges.

## 2018-06-16

Ran a 1d test with all 4 running at once. All are still running. Gdax restarted
a couple times with no response from server.

A few notes about updating:
- scanners should not be touched by user. only the pairs should be updated in
  real-time
- when i update the scanner I will have to stop the old scanner and start the
  new one manually. and I will have to stop the old one before starting the new
  one to make sure candles don't overlap and double-count volume
- when I update one scanner I will also need to update package.json and thus
  all the other scanners. I will just plan on updating all scanners at once.
- so I will import the new version into its own file, set it up, stop the old
  scanners, copy the data file, then start the new scanners
- for this reason I will want to include version in dirname so that there's not
  a dirname conflict when updating. Ex: ticker-getter-1_1-0-7/
- if something goes wrong and I need to kill one of the scanners I want to be
  able to do it without stopping the others. So I should call each scanner
  separately
- if the user makes a mistake in the pairs file I don't want it to break all the
  scanners, so I should store the pairs separately
- so all of the files should continue to stay separated like they are. I can
  possibly create some sort of script to handle all of them later

In summary:
- All scanner and pairs files should stay separated like they are and each
  scanner should be run as its own process
- Include version in dirname on aws for updating
- To update, clone new version to aws, add version to dirname, install npm, set up
  pairs, kill old scanners one at a time, copy over data, run new scanners one at
  a time (with 'nohup node scannerPoloniex &> nohupPoloniex.out &')

So I could in theory add a module to store commonly used functions and stuff,
but I need to keep the actual scanners separate.

## 2018-06-16

Next I want to talk about how I'm getting data from the websockets. On Binance
and Gdax I cycle through the ticker to get a list of all possible pairs, then
I subscribe to trade data for all pairs, then send the trade data to a function
which stores it to trades.

On Bitfinex and Poloniex I only recieve data from the pairs I'm subscribed too.
And when a new pair is added or removed I subscribe or unsubscribe from it. In
theory I could instead do what I'm doing with Gdax and Binance. This would also
probably be preferable for reasons of consistency and also because I don't really
know how the subscribe and unsubscribe methods work for each exchange.
